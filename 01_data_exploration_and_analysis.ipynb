{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption Forecasting - Data Exploration and Analysis\n",
    "\n",
    "This notebook performs comprehensive data exploration and analysis on the London Smart Meter dataset to understand energy consumption patterns and prepare for predictive modeling.\n",
    "\n",
    "## Objectives:\n",
    "- Load and explore the London Smart Meter dataset\n",
    "- Analyze energy consumption patterns and trends\n",
    "- Investigate seasonal and temporal variations\n",
    "- Examine household consumption behaviors\n",
    "- Assess data quality and completeness\n",
    "- Generate initial insights for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, jarque_bera\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set plot styles\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Loading the London Smart Meter dataset which contains energy consumption data from 5,567 London households between November 2011 and February 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main datasets\n",
    "# Note: Ensure you have downloaded the London Smart Meter dataset from Kaggle\n",
    "# Dataset URL: https://www.kaggle.com/datasets/jeanmidev/smart-meters-in-london\n",
    "\n",
    "try:\n",
    "    # Load energy consumption data (daily aggregated)\n",
    "    energy_data = pd.read_csv('../data/raw/daily_dataset.csv')\n",
    "    print(\"Daily energy dataset loaded successfully\")\n",
    "    print(f\"Shape: {energy_data.shape}\")\n",
    "    \n",
    "    # Load weather data\n",
    "    weather_data = pd.read_csv('../data/raw/weather_hourly_darksky.csv')\n",
    "    print(\"Weather dataset loaded successfully\")\n",
    "    print(f\"Shape: {weather_data.shape}\")\n",
    "    \n",
    "    # Load additional datasets if available\n",
    "    try:\n",
    "        acorn_data = pd.read_csv('../data/raw/acorn_details.csv')\n",
    "        print(\"ACORN demographic data loaded successfully\")\n",
    "        print(f\"Shape: {acorn_data.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ACORN data not found - continuing without demographic data\")\n",
    "        acorn_data = None\n",
    "    \n",
    "    try:\n",
    "        holidays_data = pd.read_csv('../data/raw/uk_bank_holidays.csv')\n",
    "        print(\"UK bank holidays data loaded successfully\")\n",
    "        print(f\"Shape: {holidays_data.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Holidays data not found - continuing without holiday data\")\n",
    "        holidays_data = None\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure you have downloaded the London Smart Meter dataset from Kaggle\")\n",
    "    print(\"Expected files in '../data/raw/':\")\n",
    "    print(\"- daily_dataset.csv\")\n",
    "    print(\"- weather_hourly_darksky.csv\")\n",
    "    print(\"- acorn_details.csv (optional)\")\n",
    "    print(\"- uk_bank_holidays.csv (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the energy dataset\n",
    "print(\"=== ENERGY CONSUMPTION DATASET OVERVIEW ===\")\n",
    "print(\"\\nDataset Shape:\", energy_data.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(energy_data.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(energy_data.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(energy_data.tail())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "energy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numerical columns\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "display(energy_data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n=== MISSING VALUES ANALYSIS ===\")\n",
    "missing_values = energy_data.isnull().sum()\n",
    "missing_percent = (missing_values / len(energy_data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(energy_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather data exploration\n",
    "print(\"=== WEATHER DATASET OVERVIEW ===\")\n",
    "print(\"\\nDataset Shape:\", weather_data.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(weather_data.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(weather_data.head())\n",
    "\n",
    "print(\"\\nWeather data statistics:\")\n",
    "display(weather_data.describe())\n",
    "\n",
    "# Weather missing values\n",
    "weather_missing = weather_data.isnull().sum()\n",
    "print(\"\\nMissing values in weather data:\")\n",
    "print(weather_missing[weather_missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "print(\"=== DATE CONVERSION ===\")\n",
    "\n",
    "# Energy data date conversion\n",
    "if 'day' in energy_data.columns:\n",
    "    energy_data['day'] = pd.to_datetime(energy_data['day'])\n",
    "    print(\"Energy data 'day' column converted to datetime\")\n",
    "elif 'date' in energy_data.columns:\n",
    "    energy_data['date'] = pd.to_datetime(energy_data['date'])\n",
    "    energy_data['day'] = energy_data['date']\n",
    "    print(\"Energy data 'date' column converted to datetime and renamed to 'day'\")\n",
    "\n",
    "# Weather data date conversion\n",
    "if 'time' in weather_data.columns:\n",
    "    weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "    print(\"Weather data 'time' column converted to datetime\")\n",
    "elif 'datetime' in weather_data.columns:\n",
    "    weather_data['datetime'] = pd.to_datetime(weather_data['datetime'])\n",
    "    weather_data['time'] = weather_data['datetime']\n",
    "    print(\"Weather data 'datetime' column converted and renamed to 'time'\")\n",
    "\n",
    "# Display date ranges\n",
    "print(f\"\\nEnergy data date range: {energy_data['day'].min()} to {energy_data['day'].max()}\")\n",
    "print(f\"Weather data date range: {weather_data['time'].min()} to {weather_data['time'].max()}\")\n",
    "print(f\"\\nTotal days in energy dataset: {(energy_data['day'].max() - energy_data['day'].min()).days + 1}\")\n",
    "print(f\"Unique days in energy dataset: {energy_data['day'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates and data quality issues\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "# Duplicate records\n",
    "energy_duplicates = energy_data.duplicated().sum()\n",
    "weather_duplicates = weather_data.duplicated().sum()\n",
    "\n",
    "print(f\"Duplicate records in energy data: {energy_duplicates}\")\n",
    "print(f\"Duplicate records in weather data: {weather_duplicates}\")\n",
    "\n",
    "# Check for negative energy consumption\n",
    "if 'energy_sum' in energy_data.columns:\n",
    "    negative_consumption = (energy_data['energy_sum'] < 0).sum()\n",
    "    zero_consumption = (energy_data['energy_sum'] == 0).sum()\n",
    "    print(f\"\\nNegative energy consumption records: {negative_consumption}\")\n",
    "    print(f\"Zero energy consumption records: {zero_consumption}\")\n",
    "    print(f\"Percentage of zero consumption: {zero_consumption/len(energy_data)*100:.2f}%\")\n",
    "\n",
    "# Basic energy consumption statistics\n",
    "if 'energy_sum' in energy_data.columns:\n",
    "    total_households = energy_data['LCLid'].nunique()\n",
    "    total_observations = len(energy_data)\n",
    "    avg_consumption = energy_data['energy_sum'].mean()\n",
    "    median_consumption = energy_data['energy_sum'].median()\n",
    "    \n",
    "    print(f\"\\n=== BASIC STATISTICS ===\")\n",
    "    print(f\"Total unique households: {total_households:,}\")\n",
    "    print(f\"Total observations: {total_observations:,}\")\n",
    "    print(f\"Average daily consumption: {avg_consumption:.2f} kWh\")\n",
    "    print(f\"Median daily consumption: {median_consumption:.2f} kWh\")\n",
    "    print(f\"Min consumption: {energy_data['energy_sum'].min():.2f} kWh\")\n",
    "    print(f\"Max consumption: {energy_data['energy_sum'].max():.2f} kWh\")\n",
    "    print(f\"Standard deviation: {energy_data['energy_sum'].std():.2f} kWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Energy Consumption Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy consumption distribution visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(energy_data['energy_sum'], bins=100, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Daily Energy Consumption', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Energy Consumption (kWh)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[0, 1].boxplot(energy_data['energy_sum'], patch_artist=True,\n",
    "                   boxprops=dict(facecolor='lightcoral', alpha=0.7))\n",
    "axes[0, 1].set_title('Box Plot of Daily Energy Consumption', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Energy Consumption (kWh)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Density plot\n",
    "energy_data['energy_sum'].plot(kind='density', ax=axes[1, 0], color='orange', linewidth=2)\n",
    "axes[1, 0].set_title('Density Plot of Energy Consumption', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Energy Consumption (kWh)')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot for normality assessment\n",
    "stats.probplot(energy_data['energy_sum'], dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot (Normal Distribution)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests for normality\n",
    "print(\"=== NORMALITY TESTS ===\")\n",
    "# Sample subset for testing (large datasets can cause issues)\n",
    "sample_data = energy_data['energy_sum'].sample(n=min(5000, len(energy_data)), random_state=42)\n",
    "\n",
    "# Shapiro-Wilk test (for smaller samples)\n",
    "if len(sample_data) <= 5000:\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(sample_data)\n",
    "    print(f\"Shapiro-Wilk test: statistic={shapiro_stat:.4f}, p-value={shapiro_p:.2e}\")\n",
    "\n",
    "# Jarque-Bera test\n",
    "jb_stat, jb_p = jarque_bera(sample_data)\n",
    "print(f\"Jarque-Bera test: statistic={jb_stat:.4f}, p-value={jb_p:.2e}\")\n",
    "\n",
    "# D'Agostino's normality test\n",
    "dag_stat, dag_p = normaltest(sample_data)\n",
    "print(f\"D'Agostino test: statistic={dag_stat:.4f}, p-value={dag_p:.2e}\")\n",
    "\n",
    "print(\"\\nNote: p-value < 0.05 suggests data is not normally distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier analysis using IQR method\n",
    "print(\"=== OUTLIER ANALYSIS ===\")\n",
    "\n",
    "Q1 = energy_data['energy_sum'].quantile(0.25)\n",
    "Q3 = energy_data['energy_sum'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = energy_data[(energy_data['energy_sum'] < lower_bound) | \n",
    "                      (energy_data['energy_sum'] > upper_bound)]\n",
    "\n",
    "print(f\"Q1 (25th percentile): {Q1:.2f} kWh\")\n",
    "print(f\"Q3 (75th percentile): {Q3:.2f} kWh\")\n",
    "print(f\"IQR: {IQR:.2f} kWh\")\n",
    "print(f\"Lower bound: {lower_bound:.2f} kWh\")\n",
    "print(f\"Upper bound: {upper_bound:.2f} kWh\")\n",
    "print(f\"\\nNumber of outliers: {len(outliers):,} ({len(outliers)/len(energy_data)*100:.2f}%)\")\n",
    "\n",
    "# Extreme values analysis\n",
    "print(f\"\\n=== EXTREME VALUES ===\")\n",
    "print(f\"Top 10 highest consumption values:\")\n",
    "top_consumption = energy_data.nlargest(10, 'energy_sum')[['LCLid', 'day', 'energy_sum']]\n",
    "display(top_consumption)\n",
    "\n",
    "print(f\"\\nBottom 10 lowest consumption values:\")\n",
    "bottom_consumption = energy_data.nsmallest(10, 'energy_sum')[['LCLid', 'day', 'energy_sum']]\n",
    "display(bottom_consumption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features\n",
    "print(\"=== TEMPORAL FEATURE ENGINEERING ===\")\n",
    "\n",
    "energy_data['year'] = energy_data['day'].dt.year\n",
    "energy_data['month'] = energy_data['day'].dt.month\n",
    "energy_data['day_of_week'] = energy_data['day'].dt.dayofweek\n",
    "energy_data['day_name'] = energy_data['day'].dt.day_name()\n",
    "energy_data['month_name'] = energy_data['day'].dt.month_name()\n",
    "energy_data['quarter'] = energy_data['day'].dt.quarter\n",
    "energy_data['week_of_year'] = energy_data['day'].dt.isocalendar().week\n",
    "energy_data['is_weekend'] = energy_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"Temporal features created:\")\n",
    "print(\"- year, month, day_of_week, day_name, month_name\")\n",
    "print(\"- quarter, week_of_year, is_weekend\")\n",
    "\n",
    "# Display unique values for verification\n",
    "print(f\"\\nData spans {energy_data['year'].nunique()} years: {sorted(energy_data['year'].unique())}\")\n",
    "print(f\"Date range: {energy_data['day'].min().strftime('%Y-%m-%d')} to {energy_data['day'].max().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series visualization - Overall consumption trends\n",
    "daily_aggregated = energy_data.groupby('day').agg({\n",
    "    'energy_sum': ['sum', 'mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "daily_aggregated.columns = ['date', 'total_consumption', 'avg_consumption', 'household_count']\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Total daily consumption\n",
    "axes[0].plot(daily_aggregated['date'], daily_aggregated['total_consumption'], \n",
    "             linewidth=1, alpha=0.8, color='blue')\n",
    "axes[0].set_title('Total Daily Energy Consumption Across All Households', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Total Consumption (kWh)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "axes[0].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "\n",
    "# Average daily consumption per household\n",
    "axes[1].plot(daily_aggregated['date'], daily_aggregated['avg_consumption'], \n",
    "             linewidth=1, alpha=0.8, color='red')\n",
    "axes[1].set_title('Average Daily Energy Consumption Per Household', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Average Consumption (kWh)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "axes[1].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "\n",
    "# Number of households reporting daily\n",
    "axes[2].plot(daily_aggregated['date'], daily_aggregated['household_count'], \n",
    "             linewidth=1, alpha=0.8, color='green')\n",
    "axes[2].set_title('Number of Households Reporting Daily', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Household Count')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "axes[2].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Daily aggregated data shape: {daily_aggregated.shape}\")\n",
    "print(f\"Average households per day: {daily_aggregated['household_count'].mean():.0f}\")\n",
    "print(f\"Max households in a day: {daily_aggregated['household_count'].max():.0f}\")\n",
    "print(f\"Min households in a day: {daily_aggregated['household_count'].min():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal patterns analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Monthly consumption patterns\n",
    "monthly_avg = energy_data.groupby('month')['energy_sum'].mean().reset_index()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "axes[0, 0].plot(monthly_avg['month'], monthly_avg['energy_sum'], \n",
    "                marker='o', linewidth=3, markersize=8, color='navy')\n",
    "axes[0, 0].set_title('Average Energy Consumption by Month', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Month')\n",
    "axes[0, 0].set_ylabel('Average Consumption (kWh)')\n",
    "axes[0, 0].set_xticks(range(1, 13))\n",
    "axes[0, 0].set_xticklabels(month_names)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Day of week patterns\n",
    "dow_avg = energy_data.groupby('day_of_week')['energy_sum'].mean().reset_index()\n",
    "dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "axes[0, 1].bar(range(7), dow_avg['energy_sum'], color='lightcoral', alpha=0.8, edgecolor='black')\n",
    "axes[0, 1].set_title('Average Energy Consumption by Day of Week', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Average Consumption (kWh)')\n",
    "axes[0, 1].set_xticks(range(7))\n",
    "axes[0, 1].set_xticklabels(dow_names, rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Quarterly patterns\n",
    "quarterly_avg = energy_data.groupby('quarter')['energy_sum'].mean().reset_index()\n",
    "quarter_names = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "axes[1, 0].bar(quarterly_avg['quarter'], quarterly_avg['energy_sum'], \n",
    "               color='lightgreen', alpha=0.8, edgecolor='black')\n",
    "axes[1, 0].set_title('Average Energy Consumption by Quarter', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Quarter')\n",
    "axes[1, 0].set_ylabel('Average Consumption (kWh)')\n",
    "axes[1, 0].set_xticks([1, 2, 3, 4])\n",
    "axes[1, 0].set_xticklabels(quarter_names)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Weekend vs Weekday comparison\n",
    "weekend_comparison = energy_data.groupby('is_weekend')['energy_sum'].mean().reset_index()\n",
    "weekend_labels = ['Weekday', 'Weekend']\n",
    "\n",
    "axes[1, 1].bar([0, 1], weekend_comparison['energy_sum'], \n",
    "               color=['lightblue', 'orange'], alpha=0.8
